{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importing Libraries, Data and Data Cleaining\n",
    "\n",
    "Download the files here: https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction/download?datasetVersionNumber=3\n",
    "\n",
    "**application_record.csv** contains a set of 18 features about **438,557** credit applicants. Some of which are duplicate records or can contain missing values. As shown in the steps below, after removing duplicates and records with missing data, the table is reduced to **304,317** applicants.\n",
    "\n",
    "**credit_record.csv** contains historical payment data, identified as follows:\n",
    "\n",
    "These two tables can be connected by the common column **ID**. However, not all applicants have data in the credit_record table. So leaving the intersect of the two datasets down to (xxx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "application_record = pd.read_csv(\"application_record.csv\")\n",
    "credit_record = pd.read_csv(\"credit_record.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Removing duplicate records and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicate records\n",
      "Number of rows and columns: (438557, 18)\n",
      "Number of duplicated records: 47\n",
      "\n",
      "After removing duplicate records\n",
      "Number of rows and columns: (438510, 18)\n",
      "Number of duplicated records: 0\n",
      "ID                     438510\n",
      "CODE_GENDER                 2\n",
      "FLAG_OWN_CAR                2\n",
      "FLAG_OWN_REALTY             2\n",
      "CNT_CHILDREN               12\n",
      "AMT_INCOME_TOTAL          866\n",
      "NAME_INCOME_TYPE            5\n",
      "NAME_EDUCATION_TYPE         5\n",
      "NAME_FAMILY_STATUS          5\n",
      "NAME_HOUSING_TYPE           6\n",
      "DAYS_BIRTH              16379\n",
      "DAYS_EMPLOYED            9406\n",
      "FLAG_MOBIL                  1\n",
      "FLAG_WORK_PHONE             2\n",
      "FLAG_PHONE                  2\n",
      "FLAG_EMAIL                  2\n",
      "OCCUPATION_TYPE            18\n",
      "CNT_FAM_MEMBERS            13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate records\n",
    "print(\"Before removing duplicate records\")\n",
    "print(\"Number of rows and columns:\", application_record.shape)\n",
    "print(\"Number of duplicated records:\", application_record.duplicated(subset=[\"ID\"]).sum())\n",
    "\n",
    "application_record = application_record.drop_duplicates(subset=[\"ID\"])\n",
    "print(\"\\nAfter removing duplicate records\")\n",
    "print(\"Number of rows and columns:\", application_record.shape)\n",
    "print(\"Number of duplicated records:\", application_record.duplicated(subset=[\"ID\"]).sum())\n",
    "print(application_record.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                          0\n",
      "CODE_GENDER                 0\n",
      "FLAG_OWN_CAR                0\n",
      "FLAG_OWN_REALTY             0\n",
      "CNT_CHILDREN                0\n",
      "AMT_INCOME_TOTAL            0\n",
      "NAME_INCOME_TYPE            0\n",
      "NAME_EDUCATION_TYPE         0\n",
      "NAME_FAMILY_STATUS          0\n",
      "NAME_HOUSING_TYPE           0\n",
      "DAYS_BIRTH                  0\n",
      "DAYS_EMPLOYED               0\n",
      "FLAG_MOBIL                  0\n",
      "FLAG_WORK_PHONE             0\n",
      "FLAG_PHONE                  0\n",
      "FLAG_EMAIL                  0\n",
      "OCCUPATION_TYPE        134193\n",
      "CNT_FAM_MEMBERS             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dealing with missing records\n",
    "print(application_record.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the only column in the application_record table that contains missing data is OCCUPATION_TYPE, with a total of 134,193 records. The data dictionary does not provide any information on why this data missing or if there is any reason behind it, for example, being unemployed. Therefore, instead of removing all those records from the dataset, let's replace those missing values with a 'Not disclosed' label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not disclosed            134193\n",
      "Laborers                  78231\n",
      "Core staff                43000\n",
      "Sales staff               41094\n",
      "Managers                  35481\n",
      "Drivers                   26090\n",
      "High skill tech staff     17285\n",
      "Accountants               15983\n",
      "Medicine staff            13518\n",
      "Cooking staff              8076\n",
      "Security staff             7993\n",
      "Cleaning staff             5843\n",
      "Private service staff      3455\n",
      "Low-skill Laborers         2140\n",
      "Secretaries                2044\n",
      "Waiters/barmen staff       1665\n",
      "Realty agents              1041\n",
      "HR staff                    774\n",
      "IT staff                    604\n",
      "Name: OCCUPATION_TYPE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "application_record[\"OCCUPATION_TYPE\"].fillna(value='Not disclosed', inplace=True)\n",
    "print(application_record['OCCUPATION_TYPE'].value_counts(dropna=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As each client normally uses the credit card for several months, duplicate values in the ID column of the *credit_record* table are expected. And as shown below, there are no missing data in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048575, 3)\n",
      "ID                45985\n",
      "MONTHS_BALANCE       61\n",
      "STATUS                8\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                0\n",
       "MONTHS_BALANCE    0\n",
       "STATUS            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicate and missing values in the credit_record data\n",
    "print(credit_record.shape)\n",
    "print(credit_record.nunique())\n",
    "credit_record.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the difference between the number of IDs on the credit_record table (45,985) and the application_record (438,510), we note that not all applicants have a credit history. Although the reason behind this is not disclosed in the data source, 3 possible reasons could explain the difference: (1) Some records could be data from new accounts, that haven't had any closed statements as of the date when the data was extracted; (2) Closed accounts for which the last closed statement was outside the data credit_record time frame; Or (3) all the bank's client data could be stored in the same datasource and not all clients might have credit cards associated with their accounts.\n",
    "\n",
    "Even if these explanations are only especulative, not having a credit record won't allow a client to be classified as good or bad creditor, and therefore, these individuals are not part of this exercise and must be removed from the dataset. This step will be addressed in the client classification variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36457"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the intersect between the two tables.\n",
    "len(set(application_record['ID']).intersection(set(credit_record['ID']))) # how many records shared?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Creating the client classification variable\n",
    "The **credit_record** table contains historical payment data identified as follows:\n",
    "\n",
    "* 0: 1-29 days past due \n",
    "* 1: 30-59 days past due \n",
    "* 2: 60-89 days overdue \n",
    "* 3: 90-119 days overdue \n",
    "* 4: 120-149 days overdue \n",
    "* 5: Overdue or bad debts, write-offs for more than 150 days \n",
    "* C: paid off that month \n",
    "* X: No loan for the month\n",
    "\n",
    "To construct the classifier label, creditors that have no overdue or bad debts, will be classified with a label 'Good'. On the contrary, i.e. if there are any payments identified with the number 5 in the status column, they will be classified as 'Bad'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying good or bad creditors\n",
    "classification = []\n",
    "for client in application_record[\"ID\"]:\n",
    "    client_history = credit_record[\"STATUS\"][credit_record[\"ID\"] == client]\n",
    "    if len(client_history) > 0:\n",
    "        flag = 'Good'\n",
    "        for payment_status in client_history:\n",
    "            if payment_status == '5':\n",
    "                flag = 'Bad'\n",
    "                break \n",
    "    else:\n",
    "        flag = 'No data'\n",
    "    classification.append(flag)\n",
    "    \n",
    "application_record['CLASSIFICATION'] = (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No data    402053\n",
       "Good        36277\n",
       "Bad           180\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_record['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36457\n",
      "36457\n"
     ]
    }
   ],
   "source": [
    "# Review classification results\n",
    "common_rows = pd.merge(application_record, credit_record, on='ID')\n",
    "common_rows.drop_duplicates(subset=[\"ID\"], inplace=True)\n",
    "num_common_rows = len(common_rows)\n",
    "print(num_common_rows)\n",
    "\n",
    "# Expected number of good and bad creditors, vs no data\n",
    "print(36277 + 180)\n",
    "\n",
    "# application_record.to_csv(\"check.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good    36277\n",
      "Bad       180\n",
      "Name: CLASSIFICATION, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Removing creditors that have no credit history\n",
    "df = application_record[application_record['CLASSIFICATION'] != 'No data']\n",
    "print(df['CLASSIFICATION'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Removing variables\n",
    "\n",
    "**ID** - The ID variable can be removed because it's a unique number assigned to each applicant and will not add value to the analysis.\n",
    "\n",
    "**FLAG_MOBIL** - Checking the variable value counts, we can see that the variable FLAG_MOBIL, which is a boolean variable that identifies if there is a mobile phone registered in the client's account, only has true values and therefore, it can be removed from our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/5ld4yk153p7419g8frs0z3qh0000gn/T/ipykernel_33838/1174668487.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=['ID', 'FLAG_MOBIL'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.FLAG_MOBIL.value_counts() # only one category\n",
    "df.drop(columns=['ID', 'FLAG_MOBIL'], inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown below, after cleaning the data, the dataset contains 36,457 rows and 17 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36457, 17)\n"
     ]
    }
   ],
   "source": [
    "# Final dataset shape and data types\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = df.drop(columns='CLASSIFICATION')\n",
    "y = df['CLASSIFICATION']\n",
    "#print(X.dtypes)\n",
    "#print(y.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Converting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({'Good': 1, 'Bad': 0})\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.CODE_GENDER = X.CODE_GENDER.astype('category')\n",
    "# X.FLAG_OWN_CAR = X.FLAG_OWN_CAR.astype('category')\n",
    "# X.FLAG_OWN_REALTY = X.FLAG_OWN_REALTY.astype('category')\n",
    "\n",
    "# X.NAME_INCOME_TYPE = X.NAME_INCOME_TYPE.astype('category')\n",
    "# X.NAME_EDUCATION_TYPE = X.NAME_EDUCATION_TYPE.astype('category')\n",
    "# X.NAME_FAMILY_STATUS = X.NAME_FAMILY_STATUS.astype('category')\n",
    "# X.NAME_HOUSING_TYPE = X.NAME_HOUSING_TYPE.astype('category')\n",
    "\n",
    "# X.FLAG_WORK_PHONE = X.FLAG_WORK_PHONE.astype('bool')\n",
    "# X.FLAG_PHONE = X.FLAG_PHONE.astype('bool')\n",
    "# X.FLAG_EMAIL = X.FLAG_EMAIL.astype('bool')\n",
    "\n",
    "# X.OCCUPATION_TYPE = X.OCCUPATION_TYPE.astype('category')\n",
    "# X.CNT_FAM_MEMBERS = X.CNT_FAM_MEMBERS.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT_CHILDREN                                           int64\n",
      "AMT_INCOME_TOTAL                                     float64\n",
      "DAYS_BIRTH                                             int64\n",
      "DAYS_EMPLOYED                                          int64\n",
      "FLAG_WORK_PHONE                                         bool\n",
      "FLAG_PHONE                                              bool\n",
      "FLAG_EMAIL                                              bool\n",
      "CNT_FAM_MEMBERS                                        int64\n",
      "CODE_GENDER_F                                          uint8\n",
      "CODE_GENDER_M                                          uint8\n",
      "FLAG_OWN_CAR_N                                         uint8\n",
      "FLAG_OWN_CAR_Y                                         uint8\n",
      "FLAG_OWN_REALTY_N                                      uint8\n",
      "FLAG_OWN_REALTY_Y                                      uint8\n",
      "NAME_INCOME_TYPE_Commercial associate                  uint8\n",
      "NAME_INCOME_TYPE_Pensioner                             uint8\n",
      "NAME_INCOME_TYPE_State servant                         uint8\n",
      "NAME_INCOME_TYPE_Student                               uint8\n",
      "NAME_INCOME_TYPE_Working                               uint8\n",
      "NAME_EDUCATION_TYPE_Academic degree                    uint8\n",
      "NAME_EDUCATION_TYPE_Higher education                   uint8\n",
      "NAME_EDUCATION_TYPE_Incomplete higher                  uint8\n",
      "NAME_EDUCATION_TYPE_Lower secondary                    uint8\n",
      "NAME_EDUCATION_TYPE_Secondary / secondary special      uint8\n",
      "NAME_FAMILY_STATUS_Civil marriage                      uint8\n",
      "NAME_FAMILY_STATUS_Married                             uint8\n",
      "NAME_FAMILY_STATUS_Separated                           uint8\n",
      "NAME_FAMILY_STATUS_Single / not married                uint8\n",
      "NAME_FAMILY_STATUS_Widow                               uint8\n",
      "NAME_HOUSING_TYPE_Co-op apartment                      uint8\n",
      "NAME_HOUSING_TYPE_House / apartment                    uint8\n",
      "NAME_HOUSING_TYPE_Municipal apartment                  uint8\n",
      "NAME_HOUSING_TYPE_Office apartment                     uint8\n",
      "NAME_HOUSING_TYPE_Rented apartment                     uint8\n",
      "NAME_HOUSING_TYPE_With parents                         uint8\n",
      "OCCUPATION_TYPE_Accountants                            uint8\n",
      "OCCUPATION_TYPE_Cleaning staff                         uint8\n",
      "OCCUPATION_TYPE_Cooking staff                          uint8\n",
      "OCCUPATION_TYPE_Core staff                             uint8\n",
      "OCCUPATION_TYPE_Drivers                                uint8\n",
      "OCCUPATION_TYPE_HR staff                               uint8\n",
      "OCCUPATION_TYPE_High skill tech staff                  uint8\n",
      "OCCUPATION_TYPE_IT staff                               uint8\n",
      "OCCUPATION_TYPE_Laborers                               uint8\n",
      "OCCUPATION_TYPE_Low-skill Laborers                     uint8\n",
      "OCCUPATION_TYPE_Managers                               uint8\n",
      "OCCUPATION_TYPE_Medicine staff                         uint8\n",
      "OCCUPATION_TYPE_Not disclosed                          uint8\n",
      "OCCUPATION_TYPE_Private service staff                  uint8\n",
      "OCCUPATION_TYPE_Realty agents                          uint8\n",
      "OCCUPATION_TYPE_Sales staff                            uint8\n",
      "OCCUPATION_TYPE_Secretaries                            uint8\n",
      "OCCUPATION_TYPE_Security staff                         uint8\n",
      "OCCUPATION_TYPE_Waiters/barmen staff                   uint8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.99 (+/- 0.00)\n",
      "Logistic Regression Accuracy: 1.00 (+/- 0.00)\n",
      "Decision Tree Accuracy: 0.99 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# Creating a 10-Fold cross-validation object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "logreg = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Performing 10-fold cross-validation for each model\n",
    "knn_scores = cross_val_score(knn, X, y, cv=kf)\n",
    "logreg_scores = cross_val_score(logreg, X, y, cv=kf)\n",
    "dt_scores = cross_val_score(dt, X, y, cv=kf)\n",
    "\n",
    "# print mean and standard deviation of each model's scores\n",
    "print(\"KNN Accuracy: %0.2f (+/- %0.2f)\" % (knn_scores.mean(), knn_scores.std() * 2))\n",
    "print(\"Logistic Regression Accuracy: %0.2f (+/- %0.2f)\" % (logreg_scores.mean(), logreg_scores.std() * 2))\n",
    "print(\"Decision Tree Accuracy: %0.2f (+/- %0.2f)\" % (dt_scores.mean(), dt_scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
